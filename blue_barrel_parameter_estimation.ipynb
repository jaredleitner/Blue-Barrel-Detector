{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains my code for obtaining the parameters of the single Gaussian classifier. The training data was labeling in MatLab using the roipoly function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize all pixels and corresponding labels into 3xN and 1xN where N is the total number of pixels or training samples. I use the last 41 images of the data set for training, and the first 5 as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 38400000)\n",
      "(38400000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.zeros((3,0))\n",
    "y_train = np.zeros((1,0))\n",
    "\n",
    "for i in range(5,45):\n",
    "    img = cv2.imread(\"trainset/%d.png\" %(i+1))\n",
    "    array_img = np.array(img)    \n",
    "    array_img = np.moveaxis(array_img, -1, 0)\n",
    "    array_img = np.reshape(array_img, (3,-1))\n",
    "    \n",
    "    img_mask = Image.open(\"trainset/%dbb.png\" %(i+1))\n",
    "    array_mask = np.array(img_mask)\n",
    "    array_mask = np.reshape(array_mask, (1,-1))\n",
    "    \n",
    "    x_train = np.append(x_train,array_img, axis = 1)\n",
    "    y_train = np.append(y_train,array_mask)#, axis = 1)\n",
    "\n",
    "N = x_train.shape[1]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate training samples corresponding to blue and not blue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 347713)\n",
      "(3, 37914963)\n",
      "38262676\n"
     ]
    }
   ],
   "source": [
    "x_train_blue = x_train[:, y_train == 1]\n",
    "print(x_train_blue.shape)\n",
    "\n",
    "x_train_not_blue = x_train[:, y_train == 0]\n",
    "print(x_train_not_blue.shape)\n",
    "\n",
    "N_blue = x_train_blue.shape[1]\n",
    "N_not_blue = x_train_not_blue.shape[1]\n",
    "print(N_blue + N_not_blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute average of blue/not blue classes. This is the MLE estimate of the mean for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115.00799798]\n",
      " [ 65.94341023]\n",
      " [ 32.35539942]]\n",
      "[[ 87.11597537]\n",
      " [ 98.0918099 ]\n",
      " [104.67259641]]\n"
     ]
    }
   ],
   "source": [
    "blue_sum = np.sum(x_train_blue, 1, keepdims=True)\n",
    "blue_average = blue_sum / x_train_blue.shape[1]\n",
    "print(blue_average)\n",
    "\n",
    "not_blue_sum = np.sum(x_train_not_blue, 1, keepdims=True)\n",
    "not_blue_average = not_blue_sum / x_train_not_blue.shape[1]\n",
    "print(not_blue_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute covariance of blue/not blue classes. This is the MLE estimate of the covariance for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 347713)\n",
      "[[3219.87199431 1866.08337731  573.04527479]\n",
      " [1866.08337731 1481.42775646  753.69162267]\n",
      " [ 573.04527479  753.69162267  875.6160161 ]]\n",
      "(3, 37914963)\n",
      "[[3834.88244176 3583.18734159 3463.34380916]\n",
      " [3583.18734159 3548.6991964  3496.48462157]\n",
      " [3463.34380916 3496.48462157 3687.20627384]]\n"
     ]
    }
   ],
   "source": [
    "blue_minus_mean = x_train_blue - blue_average\n",
    "print(blue_minus_mean.shape)\n",
    "\n",
    "blue_cov = np.dot(blue_minus_mean, blue_minus_mean.T)/ N_blue\n",
    "print(blue_cov)\n",
    "\n",
    "\n",
    "not_blue_minus_mean = x_train_not_blue - not_blue_average\n",
    "print(not_blue_minus_mean.shape)\n",
    "\n",
    "not_blue_cov = np.dot(not_blue_minus_mean, not_blue_minus_mean.T)/ N_not_blue\n",
    "print(not_blue_cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the prior probabilities of each class. Again, this is the MLE estimate for the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009055026041666667\n",
      "0.987368828125\n"
     ]
    }
   ],
   "source": [
    "blue_prior = N_blue / N\n",
    "print(blue_prior)\n",
    "\n",
    "not_blue_prior = N_not_blue / N\n",
    "print(not_blue_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of multivariate gaussian where covariance inverse and determinant are passed as arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_gauss(x, mean, cov_inv, cov_det, dim):\n",
    "    '''\n",
    "    Takes an array of one input and calculates its probability based on the Guassians parameters\n",
    "    \n",
    "    Arguments:\n",
    "    x(ndarray): single input to be plugged into pdf\n",
    "    mean(ndarray): mean of the Gaussian\n",
    "    cov(ndarray): covariance of the Gaussian\n",
    "    dim(int): dimension of the Gaussian\n",
    "    \n",
    "    Returns:\n",
    "    probs(ndarray): probabilities for each input\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(x, np.ndarray), \"x is not a numpy array\"\n",
    "    assert isinstance(mean, np.ndarray), \"mean is not a numpy array\"\n",
    "    assert isinstance(cov_inv, np.ndarray), \"cov is not a numpy array\"\n",
    "    assert isinstance(dim, int), \"dim is not a int\"\n",
    "    assert x.shape == (3,1)\n",
    "    assert mean.shape == (3,1)\n",
    "    assert cov_inv.shape == (3,3)\n",
    "    \n",
    "    \n",
    "    a = 1/np.sqrt( ((2*np.pi)**dim) * cov_det)\n",
    "    \n",
    "    minus_mean = x - mean\n",
    "    exp_term = -0.5*np.dot( np.dot(minus_mean.T, cov_inv), minus_mean)\n",
    "    exp = np.exp(exp_term)\n",
    "    \n",
    "    probs = a*exp\n",
    "    \n",
    "    return probs[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the barrel detector on both training an validation images. Validation: 1-5, Training: 6-46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from hw1_starter_code import barrel_detector\n",
    "importlib.reload(barrel_detector)\n",
    "\n",
    "#initialize barrel detector\n",
    "my_barrel_d = barrel_detector.BarrelDetector()\n",
    "\n",
    "img = cv2.imread(\"trainset/1.png\")\n",
    "#obtain the segmentation mask\n",
    "my_mask = my_barrel_d.segment_image(img)\n",
    "#obtain a list of bboxes\n",
    "rects = my_barrel_d.get_bounding_box(img)\n",
    "\n",
    "#display original image and segmented mask\n",
    "cv2.imshow('image',img)\n",
    "cv2.imshow('mask',my_mask*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cells were used to test different post-segmentation processing techniques for removing non-barrels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post segmentation processing\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "my_mask = cv2.morphologyEx(my_mask,cv2.MORPH_OPEN, kernel)\n",
    "my_mask = cv2.morphologyEx(my_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "my_mask = cv2.dilate(my_mask,kernel,iterations = 10)\n",
    "my_mask = cv2.erode(my_mask,kernel,iterations = 10)\n",
    "\n",
    "        \n",
    "cv2.imshow('mask',my_mask*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove shapes with small area\n",
    "img2,cc, hierarchy = cv2.findContours(my_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)      \n",
    "for c in cc:\n",
    "    if cv2.contourArea(c) < 500:\n",
    "        my_mask = cv2.fillPoly(my_mask, pts = [c], color=(0,0,0))\n",
    "\n",
    "cv2.imshow('mask',my_mask*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check aspect ratio\n",
    "img2,cc, hierarchy = cv2.findContours(my_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  \n",
    "for c in cc:       \n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    aspect_ratio_1 = float(w)/h\n",
    "    aspect_ratio_2 = float(h)/w\n",
    "    if aspect_ratio_1 > 1 or aspect_ratio_2 > 3:\n",
    "        my_mask = cv2.fillPoly(my_mask, pts =[c], color=(0,0,0))\n",
    "        \n",
    "cv2.imshow('mask',my_mask*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make shapes convex\n",
    "img2,cc, hierarchy = cv2.findContours(my_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)        \n",
    "for c in cc:       \n",
    "    hull = cv2.convexHull(c)\n",
    "    my_mask = cv2.fillPoly(my_mask, pts =[hull], color=(255,255,255))\n",
    "\n",
    "cv2.imshow('mask',my_mask*255)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the image with bbox(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rect in rects:\n",
    "    img = cv2.rectangle(img, (rect[0],rect[1]), (rect[2], rect[3]), (0,0,255), 3)\n",
    "      \n",
    "cv2.imshow('bboxes',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004949993726815879\n"
     ]
    }
   ],
   "source": [
    "img_ground_truth = cv2.imread(\"trainset/1bb.png\")\n",
    "img_ground_truth = np.array(img_ground_truth)  \n",
    "\n",
    "blue_count = 0\n",
    "not_blue_count = 0\n",
    "\n",
    "blue_error_count = 0\n",
    "not_blue_error_count = 0\n",
    "\n",
    "for i in range(img_ground_truth.shape[0]):\n",
    "    for j in range(img_ground_truth.shape[1]):\n",
    "        if img_ground_truth[i,j,0] == 0:\n",
    "            not_blue_count+=1\n",
    "            if my_mask[i,j] == 1:\n",
    "                not_blue_error_count+=1\n",
    "        else:\n",
    "            blue_count+=1\n",
    "            if my_mask[i,j] == 0:\n",
    "                blue_error_count+=1\n",
    "\n",
    "poe = (blue_error_count/blue_count)*blue_prior + (not_blue_error_count/not_blue_count)*not_blue_prior\n",
    "\n",
    "print(poe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
